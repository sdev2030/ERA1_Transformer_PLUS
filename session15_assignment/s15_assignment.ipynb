{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21d503e7-866d-4bb2-8a18-647623e78509",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext tensorboard\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a661307b-8162-4f51-ab4b-7caceeacaa8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sn/anaconda3/envs/fastai2022/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "from ssl import SSLSession\n",
    "from tokenize import Whitespace\n",
    "# from model_transformer import build_transformer\n",
    "from dataset import BilingualDataset, causal_mask\n",
    "from config import get_config, get_weights_file_path\n",
    "\n",
    "import torchtext.datasets as datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Huggingface datasets and tokenizers\n",
    "from datasets import load_dataset\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "\n",
    "import torchmetrics\n",
    "# Launch TensorBoard SSLSession\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c26eb19b-a1aa-4e19-91df-053823487b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import get_config\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "from model_transformer import transformerModel, saveCallback #, PrintCallback #YOLOv3\n",
    "from train import greedy_decode, get_ds\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from pytorch_lightning import LightningModule, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d0fd738-3837-4e93-8c1a-c47f42fb8bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
    "AVAIL_GPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e12ab24b-ffa8-4841-805f-fbe8ef0b8aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Length of source sentence: 309\n",
      "Max Length of target sentence: 274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import ModelSummary\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "\n",
    "num_examples = 2\n",
    "\n",
    "cfg = get_config()\n",
    "cfg['batch_size'] = 6\n",
    "cfg['preload'] = None\n",
    "cfg['num_epochs'] = 10\n",
    "\n",
    "# Make sure the weights folder exists\n",
    "Path(cfg['model_folder']).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt = get_ds(cfg)\n",
    "\n",
    "#Tensorboard\n",
    "writer = SummaryWriter(cfg['experiment_name'])\n",
    "\n",
    "model = transformerModel(cfg, tokenizer_src, tokenizer_tgt, writer, num_examples)\n",
    "\n",
    "trainer = Trainer(\n",
    "    callbacks=[ModelSummary(max_depth=-1), lr_monitor], #saveCallback()], # PrintCallback()],\n",
    "#     default_root_dir=\"/home/sn/ERAv1/checkpoints/\",\n",
    "    enable_checkpointing=True,\n",
    "    # precision=16,\n",
    "    devices=AVAIL_GPUS, \n",
    "    max_epochs=cfg['num_epochs'],\n",
    "    # limit_train_batches = 10,\n",
    "    limit_val_batches = num_examples,\n",
    "    log_every_n_steps=500\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb9ebf8a-dbca-47f1-85a7-c1a57e4bb062",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "    | Name                                                  | Type                    | Params\n",
      "----------------------------------------------------------------------------------------------------\n",
      "0   | model                                                 | Transformer             | 75.1 M\n",
      "1   | model.encoder                                         | Encoder                 | 18.9 M\n",
      "2   | model.encoder.layers                                  | ModuleList              | 18.9 M\n",
      "3   | model.encoder.layers.0                                | EncoderBlock            | 3.1 M \n",
      "4   | model.encoder.layers.0.self_attention_block           | MultiHeadAttentionBlock | 1.0 M \n",
      "5   | model.encoder.layers.0.self_attention_block.w_q       | Linear                  | 262 K \n",
      "6   | model.encoder.layers.0.self_attention_block.w_k       | Linear                  | 262 K \n",
      "7   | model.encoder.layers.0.self_attention_block.w_v       | Linear                  | 262 K \n",
      "8   | model.encoder.layers.0.self_attention_block.w_o       | Linear                  | 262 K \n",
      "9   | model.encoder.layers.0.self_attention_block.dropout   | Dropout                 | 0     \n",
      "10  | model.encoder.layers.0.feed_forward_block             | FeedForwardBlock        | 2.1 M \n",
      "11  | model.encoder.layers.0.feed_forward_block.linear_1    | Linear                  | 1.1 M \n",
      "12  | model.encoder.layers.0.feed_forward_block.dropout     | Dropout                 | 0     \n",
      "13  | model.encoder.layers.0.feed_forward_block.linear_2    | Linear                  | 1.0 M \n",
      "14  | model.encoder.layers.0.residual_connections           | ModuleList              | 4     \n",
      "15  | model.encoder.layers.0.residual_connections.0         | ResidualConnection      | 2     \n",
      "16  | model.encoder.layers.0.residual_connections.0.dropout | Dropout                 | 0     \n",
      "17  | model.encoder.layers.0.residual_connections.0.norm    | LayerNormalization      | 2     \n",
      "18  | model.encoder.layers.0.residual_connections.1         | ResidualConnection      | 2     \n",
      "19  | model.encoder.layers.0.residual_connections.1.dropout | Dropout                 | 0     \n",
      "20  | model.encoder.layers.0.residual_connections.1.norm    | LayerNormalization      | 2     \n",
      "21  | model.encoder.layers.1                                | EncoderBlock            | 3.1 M \n",
      "22  | model.encoder.layers.1.self_attention_block           | MultiHeadAttentionBlock | 1.0 M \n",
      "23  | model.encoder.layers.1.self_attention_block.w_q       | Linear                  | 262 K \n",
      "24  | model.encoder.layers.1.self_attention_block.w_k       | Linear                  | 262 K \n",
      "25  | model.encoder.layers.1.self_attention_block.w_v       | Linear                  | 262 K \n",
      "26  | model.encoder.layers.1.self_attention_block.w_o       | Linear                  | 262 K \n",
      "27  | model.encoder.layers.1.self_attention_block.dropout   | Dropout                 | 0     \n",
      "28  | model.encoder.layers.1.feed_forward_block             | FeedForwardBlock        | 2.1 M \n",
      "29  | model.encoder.layers.1.feed_forward_block.linear_1    | Linear                  | 1.1 M \n",
      "30  | model.encoder.layers.1.feed_forward_block.dropout     | Dropout                 | 0     \n",
      "31  | model.encoder.layers.1.feed_forward_block.linear_2    | Linear                  | 1.0 M \n",
      "32  | model.encoder.layers.1.residual_connections           | ModuleList              | 4     \n",
      "33  | model.encoder.layers.1.residual_connections.0         | ResidualConnection      | 2     \n",
      "34  | model.encoder.layers.1.residual_connections.0.dropout | Dropout                 | 0     \n",
      "35  | model.encoder.layers.1.residual_connections.0.norm    | LayerNormalization      | 2     \n",
      "36  | model.encoder.layers.1.residual_connections.1         | ResidualConnection      | 2     \n",
      "37  | model.encoder.layers.1.residual_connections.1.dropout | Dropout                 | 0     \n",
      "38  | model.encoder.layers.1.residual_connections.1.norm    | LayerNormalization      | 2     \n",
      "39  | model.encoder.layers.2                                | EncoderBlock            | 3.1 M \n",
      "40  | model.encoder.layers.2.self_attention_block           | MultiHeadAttentionBlock | 1.0 M \n",
      "41  | model.encoder.layers.2.self_attention_block.w_q       | Linear                  | 262 K \n",
      "42  | model.encoder.layers.2.self_attention_block.w_k       | Linear                  | 262 K \n",
      "43  | model.encoder.layers.2.self_attention_block.w_v       | Linear                  | 262 K \n",
      "44  | model.encoder.layers.2.self_attention_block.w_o       | Linear                  | 262 K \n",
      "45  | model.encoder.layers.2.self_attention_block.dropout   | Dropout                 | 0     \n",
      "46  | model.encoder.layers.2.feed_forward_block             | FeedForwardBlock        | 2.1 M \n",
      "47  | model.encoder.layers.2.feed_forward_block.linear_1    | Linear                  | 1.1 M \n",
      "48  | model.encoder.layers.2.feed_forward_block.dropout     | Dropout                 | 0     \n",
      "49  | model.encoder.layers.2.feed_forward_block.linear_2    | Linear                  | 1.0 M \n",
      "50  | model.encoder.layers.2.residual_connections           | ModuleList              | 4     \n",
      "51  | model.encoder.layers.2.residual_connections.0         | ResidualConnection      | 2     \n",
      "52  | model.encoder.layers.2.residual_connections.0.dropout | Dropout                 | 0     \n",
      "53  | model.encoder.layers.2.residual_connections.0.norm    | LayerNormalization      | 2     \n",
      "54  | model.encoder.layers.2.residual_connections.1         | ResidualConnection      | 2     \n",
      "55  | model.encoder.layers.2.residual_connections.1.dropout | Dropout                 | 0     \n",
      "56  | model.encoder.layers.2.residual_connections.1.norm    | LayerNormalization      | 2     \n",
      "57  | model.encoder.layers.3                                | EncoderBlock            | 3.1 M \n",
      "58  | model.encoder.layers.3.self_attention_block           | MultiHeadAttentionBlock | 1.0 M \n",
      "59  | model.encoder.layers.3.self_attention_block.w_q       | Linear                  | 262 K \n",
      "60  | model.encoder.layers.3.self_attention_block.w_k       | Linear                  | 262 K \n",
      "61  | model.encoder.layers.3.self_attention_block.w_v       | Linear                  | 262 K \n",
      "62  | model.encoder.layers.3.self_attention_block.w_o       | Linear                  | 262 K \n",
      "63  | model.encoder.layers.3.self_attention_block.dropout   | Dropout                 | 0     \n",
      "64  | model.encoder.layers.3.feed_forward_block             | FeedForwardBlock        | 2.1 M \n",
      "65  | model.encoder.layers.3.feed_forward_block.linear_1    | Linear                  | 1.1 M \n",
      "66  | model.encoder.layers.3.feed_forward_block.dropout     | Dropout                 | 0     \n",
      "67  | model.encoder.layers.3.feed_forward_block.linear_2    | Linear                  | 1.0 M \n",
      "68  | model.encoder.layers.3.residual_connections           | ModuleList              | 4     \n",
      "69  | model.encoder.layers.3.residual_connections.0         | ResidualConnection      | 2     \n",
      "70  | model.encoder.layers.3.residual_connections.0.dropout | Dropout                 | 0     \n",
      "71  | model.encoder.layers.3.residual_connections.0.norm    | LayerNormalization      | 2     \n",
      "72  | model.encoder.layers.3.residual_connections.1         | ResidualConnection      | 2     \n",
      "73  | model.encoder.layers.3.residual_connections.1.dropout | Dropout                 | 0     \n",
      "74  | model.encoder.layers.3.residual_connections.1.norm    | LayerNormalization      | 2     \n",
      "75  | model.encoder.layers.4                                | EncoderBlock            | 3.1 M \n",
      "76  | model.encoder.layers.4.self_attention_block           | MultiHeadAttentionBlock | 1.0 M \n",
      "77  | model.encoder.layers.4.self_attention_block.w_q       | Linear                  | 262 K \n",
      "78  | model.encoder.layers.4.self_attention_block.w_k       | Linear                  | 262 K \n",
      "79  | model.encoder.layers.4.self_attention_block.w_v       | Linear                  | 262 K \n",
      "80  | model.encoder.layers.4.self_attention_block.w_o       | Linear                  | 262 K \n",
      "81  | model.encoder.layers.4.self_attention_block.dropout   | Dropout                 | 0     \n",
      "82  | model.encoder.layers.4.feed_forward_block             | FeedForwardBlock        | 2.1 M \n",
      "83  | model.encoder.layers.4.feed_forward_block.linear_1    | Linear                  | 1.1 M \n",
      "84  | model.encoder.layers.4.feed_forward_block.dropout     | Dropout                 | 0     \n",
      "85  | model.encoder.layers.4.feed_forward_block.linear_2    | Linear                  | 1.0 M \n",
      "86  | model.encoder.layers.4.residual_connections           | ModuleList              | 4     \n",
      "87  | model.encoder.layers.4.residual_connections.0         | ResidualConnection      | 2     \n",
      "88  | model.encoder.layers.4.residual_connections.0.dropout | Dropout                 | 0     \n",
      "89  | model.encoder.layers.4.residual_connections.0.norm    | LayerNormalization      | 2     \n",
      "90  | model.encoder.layers.4.residual_connections.1         | ResidualConnection      | 2     \n",
      "91  | model.encoder.layers.4.residual_connections.1.dropout | Dropout                 | 0     \n",
      "92  | model.encoder.layers.4.residual_connections.1.norm    | LayerNormalization      | 2     \n",
      "93  | model.encoder.layers.5                                | EncoderBlock            | 3.1 M \n",
      "94  | model.encoder.layers.5.self_attention_block           | MultiHeadAttentionBlock | 1.0 M \n",
      "95  | model.encoder.layers.5.self_attention_block.w_q       | Linear                  | 262 K \n",
      "96  | model.encoder.layers.5.self_attention_block.w_k       | Linear                  | 262 K \n",
      "97  | model.encoder.layers.5.self_attention_block.w_v       | Linear                  | 262 K \n",
      "98  | model.encoder.layers.5.self_attention_block.w_o       | Linear                  | 262 K \n",
      "99  | model.encoder.layers.5.self_attention_block.dropout   | Dropout                 | 0     \n",
      "100 | model.encoder.layers.5.feed_forward_block             | FeedForwardBlock        | 2.1 M \n",
      "101 | model.encoder.layers.5.feed_forward_block.linear_1    | Linear                  | 1.1 M \n",
      "102 | model.encoder.layers.5.feed_forward_block.dropout     | Dropout                 | 0     \n",
      "103 | model.encoder.layers.5.feed_forward_block.linear_2    | Linear                  | 1.0 M \n",
      "104 | model.encoder.layers.5.residual_connections           | ModuleList              | 4     \n",
      "105 | model.encoder.layers.5.residual_connections.0         | ResidualConnection      | 2     \n",
      "106 | model.encoder.layers.5.residual_connections.0.dropout | Dropout                 | 0     \n",
      "107 | model.encoder.layers.5.residual_connections.0.norm    | LayerNormalization      | 2     \n",
      "108 | model.encoder.layers.5.residual_connections.1         | ResidualConnection      | 2     \n",
      "109 | model.encoder.layers.5.residual_connections.1.dropout | Dropout                 | 0     \n",
      "110 | model.encoder.layers.5.residual_connections.1.norm    | LayerNormalization      | 2     \n",
      "111 | model.encoder.norm                                    | LayerNormalization      | 2     \n",
      "112 | model.decoder                                         | Decoder                 | 25.2 M\n",
      "113 | model.decoder.layers                                  | ModuleList              | 25.2 M\n",
      "114 | model.decoder.layers.0                                | DecoderBlock            | 4.2 M \n",
      "115 | model.decoder.layers.0.self_attention_block           | MultiHeadAttentionBlock | 1.0 M \n",
      "116 | model.decoder.layers.0.self_attention_block.w_q       | Linear                  | 262 K \n",
      "117 | model.decoder.layers.0.self_attention_block.w_k       | Linear                  | 262 K \n",
      "118 | model.decoder.layers.0.self_attention_block.w_v       | Linear                  | 262 K \n",
      "119 | model.decoder.layers.0.self_attention_block.w_o       | Linear                  | 262 K \n",
      "120 | model.decoder.layers.0.self_attention_block.dropout   | Dropout                 | 0     \n",
      "121 | model.decoder.layers.0.cross_attentioin_block         | MultiHeadAttentionBlock | 1.0 M \n",
      "122 | model.decoder.layers.0.cross_attentioin_block.w_q     | Linear                  | 262 K \n",
      "123 | model.decoder.layers.0.cross_attentioin_block.w_k     | Linear                  | 262 K \n",
      "124 | model.decoder.layers.0.cross_attentioin_block.w_v     | Linear                  | 262 K \n",
      "125 | model.decoder.layers.0.cross_attentioin_block.w_o     | Linear                  | 262 K \n",
      "126 | model.decoder.layers.0.cross_attentioin_block.dropout | Dropout                 | 0     \n",
      "127 | model.decoder.layers.0.feed_forward_block             | FeedForwardBlock        | 2.1 M \n",
      "128 | model.decoder.layers.0.feed_forward_block.linear_1    | Linear                  | 1.1 M \n",
      "129 | model.decoder.layers.0.feed_forward_block.dropout     | Dropout                 | 0     \n",
      "130 | model.decoder.layers.0.feed_forward_block.linear_2    | Linear                  | 1.0 M \n",
      "131 | model.decoder.layers.0.residual_connections           | ModuleList              | 6     \n",
      "132 | model.decoder.layers.0.residual_connections.0         | ResidualConnection      | 2     \n",
      "133 | model.decoder.layers.0.residual_connections.0.dropout | Dropout                 | 0     \n",
      "134 | model.decoder.layers.0.residual_connections.0.norm    | LayerNormalization      | 2     \n",
      "135 | model.decoder.layers.0.residual_connections.1         | ResidualConnection      | 2     \n",
      "136 | model.decoder.layers.0.residual_connections.1.dropout | Dropout                 | 0     \n",
      "137 | model.decoder.layers.0.residual_connections.1.norm    | LayerNormalization      | 2     \n",
      "138 | model.decoder.layers.0.residual_connections.2         | ResidualConnection      | 2     \n",
      "139 | model.decoder.layers.0.residual_connections.2.dropout | Dropout                 | 0     \n",
      "140 | model.decoder.layers.0.residual_connections.2.norm    | LayerNormalization      | 2     \n",
      "141 | model.decoder.layers.1                                | DecoderBlock            | 4.2 M \n",
      "142 | model.decoder.layers.1.self_attention_block           | MultiHeadAttentionBlock | 1.0 M \n",
      "143 | model.decoder.layers.1.self_attention_block.w_q       | Linear                  | 262 K \n",
      "144 | model.decoder.layers.1.self_attention_block.w_k       | Linear                  | 262 K \n",
      "145 | model.decoder.layers.1.self_attention_block.w_v       | Linear                  | 262 K \n",
      "146 | model.decoder.layers.1.self_attention_block.w_o       | Linear                  | 262 K \n",
      "147 | model.decoder.layers.1.self_attention_block.dropout   | Dropout                 | 0     \n",
      "148 | model.decoder.layers.1.cross_attentioin_block         | MultiHeadAttentionBlock | 1.0 M \n",
      "149 | model.decoder.layers.1.cross_attentioin_block.w_q     | Linear                  | 262 K \n",
      "150 | model.decoder.layers.1.cross_attentioin_block.w_k     | Linear                  | 262 K \n",
      "151 | model.decoder.layers.1.cross_attentioin_block.w_v     | Linear                  | 262 K \n",
      "152 | model.decoder.layers.1.cross_attentioin_block.w_o     | Linear                  | 262 K \n",
      "153 | model.decoder.layers.1.cross_attentioin_block.dropout | Dropout                 | 0     \n",
      "154 | model.decoder.layers.1.feed_forward_block             | FeedForwardBlock        | 2.1 M \n",
      "155 | model.decoder.layers.1.feed_forward_block.linear_1    | Linear                  | 1.1 M \n",
      "156 | model.decoder.layers.1.feed_forward_block.dropout     | Dropout                 | 0     \n",
      "157 | model.decoder.layers.1.feed_forward_block.linear_2    | Linear                  | 1.0 M \n",
      "158 | model.decoder.layers.1.residual_connections           | ModuleList              | 6     \n",
      "159 | model.decoder.layers.1.residual_connections.0         | ResidualConnection      | 2     \n",
      "160 | model.decoder.layers.1.residual_connections.0.dropout | Dropout                 | 0     \n",
      "161 | model.decoder.layers.1.residual_connections.0.norm    | LayerNormalization      | 2     \n",
      "162 | model.decoder.layers.1.residual_connections.1         | ResidualConnection      | 2     \n",
      "163 | model.decoder.layers.1.residual_connections.1.dropout | Dropout                 | 0     \n",
      "164 | model.decoder.layers.1.residual_connections.1.norm    | LayerNormalization      | 2     \n",
      "165 | model.decoder.layers.1.residual_connections.2         | ResidualConnection      | 2     \n",
      "166 | model.decoder.layers.1.residual_connections.2.dropout | Dropout                 | 0     \n",
      "167 | model.decoder.layers.1.residual_connections.2.norm    | LayerNormalization      | 2     \n",
      "168 | model.decoder.layers.2                                | DecoderBlock            | 4.2 M \n",
      "169 | model.decoder.layers.2.self_attention_block           | MultiHeadAttentionBlock | 1.0 M \n",
      "170 | model.decoder.layers.2.self_attention_block.w_q       | Linear                  | 262 K \n",
      "171 | model.decoder.layers.2.self_attention_block.w_k       | Linear                  | 262 K \n",
      "172 | model.decoder.layers.2.self_attention_block.w_v       | Linear                  | 262 K \n",
      "173 | model.decoder.layers.2.self_attention_block.w_o       | Linear                  | 262 K \n",
      "174 | model.decoder.layers.2.self_attention_block.dropout   | Dropout                 | 0     \n",
      "175 | model.decoder.layers.2.cross_attentioin_block         | MultiHeadAttentionBlock | 1.0 M \n",
      "176 | model.decoder.layers.2.cross_attentioin_block.w_q     | Linear                  | 262 K \n",
      "177 | model.decoder.layers.2.cross_attentioin_block.w_k     | Linear                  | 262 K \n",
      "178 | model.decoder.layers.2.cross_attentioin_block.w_v     | Linear                  | 262 K \n",
      "179 | model.decoder.layers.2.cross_attentioin_block.w_o     | Linear                  | 262 K \n",
      "180 | model.decoder.layers.2.cross_attentioin_block.dropout | Dropout                 | 0     \n",
      "181 | model.decoder.layers.2.feed_forward_block             | FeedForwardBlock        | 2.1 M \n",
      "182 | model.decoder.layers.2.feed_forward_block.linear_1    | Linear                  | 1.1 M \n",
      "183 | model.decoder.layers.2.feed_forward_block.dropout     | Dropout                 | 0     \n",
      "184 | model.decoder.layers.2.feed_forward_block.linear_2    | Linear                  | 1.0 M \n",
      "185 | model.decoder.layers.2.residual_connections           | ModuleList              | 6     \n",
      "186 | model.decoder.layers.2.residual_connections.0         | ResidualConnection      | 2     \n",
      "187 | model.decoder.layers.2.residual_connections.0.dropout | Dropout                 | 0     \n",
      "188 | model.decoder.layers.2.residual_connections.0.norm    | LayerNormalization      | 2     \n",
      "189 | model.decoder.layers.2.residual_connections.1         | ResidualConnection      | 2     \n",
      "190 | model.decoder.layers.2.residual_connections.1.dropout | Dropout                 | 0     \n",
      "191 | model.decoder.layers.2.residual_connections.1.norm    | LayerNormalization      | 2     \n",
      "192 | model.decoder.layers.2.residual_connections.2         | ResidualConnection      | 2     \n",
      "193 | model.decoder.layers.2.residual_connections.2.dropout | Dropout                 | 0     \n",
      "194 | model.decoder.layers.2.residual_connections.2.norm    | LayerNormalization      | 2     \n",
      "195 | model.decoder.layers.3                                | DecoderBlock            | 4.2 M \n",
      "196 | model.decoder.layers.3.self_attention_block           | MultiHeadAttentionBlock | 1.0 M \n",
      "197 | model.decoder.layers.3.self_attention_block.w_q       | Linear                  | 262 K \n",
      "198 | model.decoder.layers.3.self_attention_block.w_k       | Linear                  | 262 K \n",
      "199 | model.decoder.layers.3.self_attention_block.w_v       | Linear                  | 262 K \n",
      "200 | model.decoder.layers.3.self_attention_block.w_o       | Linear                  | 262 K \n",
      "201 | model.decoder.layers.3.self_attention_block.dropout   | Dropout                 | 0     \n",
      "202 | model.decoder.layers.3.cross_attentioin_block         | MultiHeadAttentionBlock | 1.0 M \n",
      "203 | model.decoder.layers.3.cross_attentioin_block.w_q     | Linear                  | 262 K \n",
      "204 | model.decoder.layers.3.cross_attentioin_block.w_k     | Linear                  | 262 K \n",
      "205 | model.decoder.layers.3.cross_attentioin_block.w_v     | Linear                  | 262 K \n",
      "206 | model.decoder.layers.3.cross_attentioin_block.w_o     | Linear                  | 262 K \n",
      "207 | model.decoder.layers.3.cross_attentioin_block.dropout | Dropout                 | 0     \n",
      "208 | model.decoder.layers.3.feed_forward_block             | FeedForwardBlock        | 2.1 M \n",
      "209 | model.decoder.layers.3.feed_forward_block.linear_1    | Linear                  | 1.1 M \n",
      "210 | model.decoder.layers.3.feed_forward_block.dropout     | Dropout                 | 0     \n",
      "211 | model.decoder.layers.3.feed_forward_block.linear_2    | Linear                  | 1.0 M \n",
      "212 | model.decoder.layers.3.residual_connections           | ModuleList              | 6     \n",
      "213 | model.decoder.layers.3.residual_connections.0         | ResidualConnection      | 2     \n",
      "214 | model.decoder.layers.3.residual_connections.0.dropout | Dropout                 | 0     \n",
      "215 | model.decoder.layers.3.residual_connections.0.norm    | LayerNormalization      | 2     \n",
      "216 | model.decoder.layers.3.residual_connections.1         | ResidualConnection      | 2     \n",
      "217 | model.decoder.layers.3.residual_connections.1.dropout | Dropout                 | 0     \n",
      "218 | model.decoder.layers.3.residual_connections.1.norm    | LayerNormalization      | 2     \n",
      "219 | model.decoder.layers.3.residual_connections.2         | ResidualConnection      | 2     \n",
      "220 | model.decoder.layers.3.residual_connections.2.dropout | Dropout                 | 0     \n",
      "221 | model.decoder.layers.3.residual_connections.2.norm    | LayerNormalization      | 2     \n",
      "222 | model.decoder.layers.4                                | DecoderBlock            | 4.2 M \n",
      "223 | model.decoder.layers.4.self_attention_block           | MultiHeadAttentionBlock | 1.0 M \n",
      "224 | model.decoder.layers.4.self_attention_block.w_q       | Linear                  | 262 K \n",
      "225 | model.decoder.layers.4.self_attention_block.w_k       | Linear                  | 262 K \n",
      "226 | model.decoder.layers.4.self_attention_block.w_v       | Linear                  | 262 K \n",
      "227 | model.decoder.layers.4.self_attention_block.w_o       | Linear                  | 262 K \n",
      "228 | model.decoder.layers.4.self_attention_block.dropout   | Dropout                 | 0     \n",
      "229 | model.decoder.layers.4.cross_attentioin_block         | MultiHeadAttentionBlock | 1.0 M \n",
      "230 | model.decoder.layers.4.cross_attentioin_block.w_q     | Linear                  | 262 K \n",
      "231 | model.decoder.layers.4.cross_attentioin_block.w_k     | Linear                  | 262 K \n",
      "232 | model.decoder.layers.4.cross_attentioin_block.w_v     | Linear                  | 262 K \n",
      "233 | model.decoder.layers.4.cross_attentioin_block.w_o     | Linear                  | 262 K \n",
      "234 | model.decoder.layers.4.cross_attentioin_block.dropout | Dropout                 | 0     \n",
      "235 | model.decoder.layers.4.feed_forward_block             | FeedForwardBlock        | 2.1 M \n",
      "236 | model.decoder.layers.4.feed_forward_block.linear_1    | Linear                  | 1.1 M \n",
      "237 | model.decoder.layers.4.feed_forward_block.dropout     | Dropout                 | 0     \n",
      "238 | model.decoder.layers.4.feed_forward_block.linear_2    | Linear                  | 1.0 M \n",
      "239 | model.decoder.layers.4.residual_connections           | ModuleList              | 6     \n",
      "240 | model.decoder.layers.4.residual_connections.0         | ResidualConnection      | 2     \n",
      "241 | model.decoder.layers.4.residual_connections.0.dropout | Dropout                 | 0     \n",
      "242 | model.decoder.layers.4.residual_connections.0.norm    | LayerNormalization      | 2     \n",
      "243 | model.decoder.layers.4.residual_connections.1         | ResidualConnection      | 2     \n",
      "244 | model.decoder.layers.4.residual_connections.1.dropout | Dropout                 | 0     \n",
      "245 | model.decoder.layers.4.residual_connections.1.norm    | LayerNormalization      | 2     \n",
      "246 | model.decoder.layers.4.residual_connections.2         | ResidualConnection      | 2     \n",
      "247 | model.decoder.layers.4.residual_connections.2.dropout | Dropout                 | 0     \n",
      "248 | model.decoder.layers.4.residual_connections.2.norm    | LayerNormalization      | 2     \n",
      "249 | model.decoder.layers.5                                | DecoderBlock            | 4.2 M \n",
      "250 | model.decoder.layers.5.self_attention_block           | MultiHeadAttentionBlock | 1.0 M \n",
      "251 | model.decoder.layers.5.self_attention_block.w_q       | Linear                  | 262 K \n",
      "252 | model.decoder.layers.5.self_attention_block.w_k       | Linear                  | 262 K \n",
      "253 | model.decoder.layers.5.self_attention_block.w_v       | Linear                  | 262 K \n",
      "254 | model.decoder.layers.5.self_attention_block.w_o       | Linear                  | 262 K \n",
      "255 | model.decoder.layers.5.self_attention_block.dropout   | Dropout                 | 0     \n",
      "256 | model.decoder.layers.5.cross_attentioin_block         | MultiHeadAttentionBlock | 1.0 M \n",
      "257 | model.decoder.layers.5.cross_attentioin_block.w_q     | Linear                  | 262 K \n",
      "258 | model.decoder.layers.5.cross_attentioin_block.w_k     | Linear                  | 262 K \n",
      "259 | model.decoder.layers.5.cross_attentioin_block.w_v     | Linear                  | 262 K \n",
      "260 | model.decoder.layers.5.cross_attentioin_block.w_o     | Linear                  | 262 K \n",
      "261 | model.decoder.layers.5.cross_attentioin_block.dropout | Dropout                 | 0     \n",
      "262 | model.decoder.layers.5.feed_forward_block             | FeedForwardBlock        | 2.1 M \n",
      "263 | model.decoder.layers.5.feed_forward_block.linear_1    | Linear                  | 1.1 M \n",
      "264 | model.decoder.layers.5.feed_forward_block.dropout     | Dropout                 | 0     \n",
      "265 | model.decoder.layers.5.feed_forward_block.linear_2    | Linear                  | 1.0 M \n",
      "266 | model.decoder.layers.5.residual_connections           | ModuleList              | 6     \n",
      "267 | model.decoder.layers.5.residual_connections.0         | ResidualConnection      | 2     \n",
      "268 | model.decoder.layers.5.residual_connections.0.dropout | Dropout                 | 0     \n",
      "269 | model.decoder.layers.5.residual_connections.0.norm    | LayerNormalization      | 2     \n",
      "270 | model.decoder.layers.5.residual_connections.1         | ResidualConnection      | 2     \n",
      "271 | model.decoder.layers.5.residual_connections.1.dropout | Dropout                 | 0     \n",
      "272 | model.decoder.layers.5.residual_connections.1.norm    | LayerNormalization      | 2     \n",
      "273 | model.decoder.layers.5.residual_connections.2         | ResidualConnection      | 2     \n",
      "274 | model.decoder.layers.5.residual_connections.2.dropout | Dropout                 | 0     \n",
      "275 | model.decoder.layers.5.residual_connections.2.norm    | LayerNormalization      | 2     \n",
      "276 | model.decoder.norm                                    | LayerNormalization      | 2     \n",
      "277 | model.src_embed                                       | InputEmbeddings         | 8.0 M \n",
      "278 | model.src_embed.embedding                             | Embedding               | 8.0 M \n",
      "279 | model.tgt_embed                                       | InputEmbeddings         | 11.5 M\n",
      "280 | model.tgt_embed.embedding                             | Embedding               | 11.5 M\n",
      "281 | model.src_pos                                         | PositionalEncoding      | 0     \n",
      "282 | model.src_pos.dropout                                 | Dropout                 | 0     \n",
      "283 | model.tgt_pos                                         | PositionalEncoding      | 0     \n",
      "284 | model.tgt_pos.dropout                                 | Dropout                 | 0     \n",
      "285 | model.projection_layer                                | ProjectionLayer         | 11.5 M\n",
      "286 | model.projection_layer.proj                           | Linear                  | 11.5 M\n",
      "287 | loss_fn                                               | CrossEntropyLoss        | 0     \n",
      "----------------------------------------------------------------------------------------------------\n",
      "75.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "75.1 M    Total params\n",
      "300.532   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: Several wealthy and benevolent individuals in the county subscribed largely for the erection of a more convenient building in a better situation; new regulations were made; improvements in diet and clothing introduced; the funds of the school were intrusted to the management of a committee.\n",
      "    TARGET: Molte benefiche e ricche persone della Contea riunirono una somma, che permise di ricostruire Lowood in modo più conveniente ed in posizione più salubre, furono fatti nuovi regolamenti, si migliorò il cibo e le vesti, e i fondi della scuola vennero affidati a un comitato.\n",
      " PREDICTED: Peggio congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture Peggio Peggio congetture Peggio congetture Peggio congetture Peggio Peggio congetture Peggio congetture Peggio congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture Peggio genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere congetture congetture congetture congetture congetture congetture congetture congetture genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere signorina Peggio genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere signorina signorina signorina signorina signorina Peggio signorina signorina signorina Peggio genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere genere Peggio Peggio Peggio Peggio genere genere genere genere genere genere genere genere signorina signorina Peggio signorina Peggio signorina Peggio signorina Peggio Peggio Peggio genere genere genere genere genere Peggio Peggio Peggio genere genere genere genere genere signorina signorina\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: There are hosts of aspirants who aim at mixing those two professions but I am not one of them!'\n",
      "    TARGET: Un’infinità di persone ama confondere queste due funzioni, io non sono fra queste.\n",
      " PREDICTED: Peggio Rispose affezione Rispose congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture Peggio Peggio Peggio Peggio Peggio congetture Peggio Peggio Peggio Peggio congetture Peggio congetture Peggio congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture congetture Peggio congetture Rispose congetture congetture congetture congetture congetture congetture Rispose affezione signorina Peggio riscattato affezione affezione affezione affezione trascurati trascurati trascurati facevano congetture Peggio Peggio Peggio Peggio Peggio congetture Peggio Peggio Peggio Peggio signorina signorina signorina signorina signorina signorina Peggio congetture Rispose affezione congetture congetture congetture congetture congetture signorina signorina signorina signorina signorina signorina signorina signorina signorina signorina signorina signorina Rispose Rispose Rispose affezione signorina signorina signorina Peggio Rispose congetture Rispose signorina Peggio signorina Peggio signorina Peggio signorina signorina signorina Peggio signorina Peggio signorina Peggio signorina Peggio Peggio signorina signorina signorina signorina signorina signorina Peggio signorina signorina signorina signorina signorina Peggio signorina Peggio signorina signorina signorina signorina signorina signorina signorina signorina signorina signorina signorina signorina signorina signorina signorina signorina Peggio signorina signorina signorina signorina signorina signorina signorina signorina signorina signorina signorina signorina signorina feltro signorina Peggio signorina Peggio signorina signorina signorina signorina signorina signorina signorina signorina signorina signorina signorina Peggio signorina Peggio signorina Peggio signorina signorina signorina signorina Peggio signorina signorina signorina signorina signorina signorina signorina signorina signorina signorina signorina signorina signorina signorina signorina signorina signorina signorina signorina signorina signorina signorina signorina Rispose Rispose Rispose signorina signorina signorina signorina signorina signorina signorina signorina Peggio signorina Peggio signorina Peggio signorina Peggio signorina Peggio signorina signorina signorina signorina signorina signorina signorina signorina signorina signorina Peggio signorina Peggio signorina signorina signorina Peggio signorina Peggio signorina Peggio signorina signorina Peggio signorina Peggio Peggio Peggio Peggio Peggio signorina Peggio signorina signorina signorina signorina signorina signorina signorina signorina signorina signorina Peggio signorina signorina signorina Peggio signorina Peggio signorina signorina signorina signorina signorina Peggio signorina Peggio signorina signorina signorina signorina signorina Peggio signorina signorina signorina signorina signorina signorina signorina signorina signorina signorina signorina signorina signorina signorina signorina signorina Peggio Peggio Peggio signorina Peggio signorina signorina signorina signorina signorina signorina signorina\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1699fb4f3b6a4f5fbeafc38ed678cf00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: He rubbed his eyes, and looked hard at me.\n",
      "    TARGET: Si stropicciò gli occhi e mi guardò fisso.\n",
      " PREDICTED: La principessa era un ’ altra .\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: Again remembering Karenin, she also remembered her illness after her confinement, and the feeling that never left her at that time.\n",
      "    TARGET: Ricordando ancora una volta Aleksej Aleksandrovic, ricordò anche il tempo della propria malattia, dopo il parto, e quel sentimento che allora non la lasciava. “Perché non sono morta?”.\n",
      " PREDICTED: Levin era stato stato , ma non aveva fatto più stato stato , ma non aveva fatto più stato stato più di lui .\n",
      "--------------------------------------------------------------------------------\n",
      "Creating Checkpoint..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: The house presented two pointed gables in its front; the windows were latticed and narrow: the front door was narrow too, one step led up to it.\n",
      "    TARGET: La casa, vista di faccia, aveva due torrette nel centro; le finestre erano strette e munite d'inferriate, la porta era pure angusta e vi si saliva con uno scalino.\n",
      " PREDICTED: Il sole si , e il signor Rochester , e il signor Rochester era un ' altra poltrona , e il viso di un cappello .\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: 'He arrived to-day, Maman.'\n",
      "    TARGET: — Oggi, maman.\n",
      " PREDICTED: — È un ’ altra cosa .\n",
      "--------------------------------------------------------------------------------\n",
      "Creating Checkpoint..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: 'Well, and what did you think about me?\n",
      "    TARGET: — Ma cosa pensavi mai di me?\n",
      " PREDICTED: — E che cosa mi ha detto che cosa mi ha detto ?\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: I feel I can easily and naturally make room in my heart for you, as my third and youngest sister.\"\n",
      "    TARGET: Sento che potrò darvi un posto nel mio cuore e considerarvi come una sorella minore.\n",
      " PREDICTED: Mi pare che sia un ' espressione di lei e di , e che vi il mio marito .\n",
      "--------------------------------------------------------------------------------\n",
      "Creating Checkpoint..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: THE BALL HAD ONLY JUST BEGUN when Kitty and her mother ascended the broad staircase which was deluged with light, decorated with flowering plants, and occupied by powdered footmen in red liveries.\n",
      "    TARGET: Il ballo era appena cominciato quando Kitty, accompagnata dalla madre, faceva il suo ingresso sulla scala grande inondata di luce e piena di fiori e di servitori incipriati e in giacca rossa.\n",
      " PREDICTED: La sera , quando Kitty aveva avuto la madre , quando la madre era aperta , la porta della madre , la , e la , con la schiena , e la .\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: 'Thank you,' replied Karenin. 'What a beautiful day it is,' he added, laying, as was his wont, peculiar stress on the word 'beautiful.'\n",
      "    TARGET: — Vi ringrazio — rispose Aleksej Aleksandrovic. — Che bella giornata! — soggiunse, secondo la sua abitudine, sottolineando in modo particolare la parola “bella”.\n",
      " PREDICTED: — Aspetta — disse Aleksej Aleksandrovic . — Ma è un giorno che è un ’ altra cosa — è un uomo che è molto contento di , come la parola .\n",
      "--------------------------------------------------------------------------------\n",
      "Creating Checkpoint..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: I went down afterwards into Yorkshire; but my father was dead, and my mother and all the family extinct, except that I found two sisters, and two of the children of one of my brothers; and as I had been long ago given over for dead, there had been no provision made for me; so that, in a word, I found nothing to relieve or assist me; and that the little money I had would not do much for me as to settling in the world.\n",
      "    TARGET: Trasferitomi indi nella contea di York, trovai morti mio fratello e mia madre; in somma estinta l’intera mia famiglia, eccetto due sorelle e due figli d’uno de’ miei fratelli. Essendo io stato creduto morto per sì lungo tempo, nulla vi rimaneva della mia parte; in guisa che, non potendo qui far conto su nulla, lo scarso danaro portatomi poteva aiutarmi ben poco a stabilirmi nel mondo.\n",
      " PREDICTED: a casa , ma in principio mi trovai in mente , e la madre , e la madre non mi aveva avuto la famiglia , e la mia famiglia , e la mia famiglia , e la mia famiglia , e la mia famiglia , e la mia famiglia , come se fossi stata stata stata stata stata stata in casa , non avrei avuto la mia casa , e non mi aveva detto che non avrei avuto il diritto di , e che non avrei avuto la mia casa , e non avrei avuto la mia casa .\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: I had scarce tied the strings of the portfolio, when, looking at his watch, he said abruptly-- \"It is nine o'clock: what are you about, Miss Eyre, to let Adele sit up so long?\n",
      "    TARGET: Avevo appena legato la cartella che egli, guardando l'orologio, disse bruscamente: — Sono le nove; perché fate vegliare Adele così lungamente?\n",
      " PREDICTED: Mi ero in fretta , quando il libro si mise a guardare , e disse : — Adele , Adele , che vi è stato ?\n",
      "--------------------------------------------------------------------------------\n",
      "Creating Checkpoint..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: It struck me that his hand looked wasted like his face.\n",
      "    TARGET: Ma la mano era posata sul mento e sulla bocca: pensava.\n",
      " PREDICTED: Mi accostai al braccio di lui , come se mi fosse la sua faccia .\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: He told me he would go if I would go with him. “I go!” says I; “why, they will eat me if I come there.”\n",
      "    TARGET: S’intendeva dire che gli avrebbe informati del modo con che aveva uccisi i suoi nemici e gli aveva salvata la vita.\n",
      " PREDICTED: a me , se mi avesse lasciato andare , gli dissi : — « Che cosa mi ! — « Me ne !\n",
      "--------------------------------------------------------------------------------\n",
      "Creating Checkpoint..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: Why it did not upset I am unable to offer any reason.\n",
      "    TARGET: Non so dare alcuna ragione del perchè non si rovesciasse.\n",
      " PREDICTED: Perché non ho fatto nulla di male , non ho potuto vivere .\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: \"Will you walk this way, ma'am?\" said the girl; and I followed her across a square hall with high doors all round: she ushered me into a room whose double illumination of fire and candle at first dazzled me, contrasting as it did with the darkness to which my eyes had been for two hours inured; when I could see, however, a cosy and agreeable picture presented itself to my view.\n",
      "    TARGET: — Di qui, signora, — mi disse la donna e fecemi traversare una stanza quadra, circondata da porte altissime, poi m'introdusse in una camera illuminata dal fuoco e dalle candele. Rimasi abbacinata perché da più ore ero al buio.\n",
      " PREDICTED: — Vi a camminare , signora Fairfax ? — mi domandò la bimba e la signora Dent , e la quale aveva aperta la sala rossa , perché mi aveva nella sala da letto e che avevo trovato in un ' altra luce . — Mi avete sentita da un ' altra volta , — mi disse , — che avevo trovato un ' altra volta , e mi pareva che non potevo .\n",
      "--------------------------------------------------------------------------------\n",
      "Creating Checkpoint..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: Even Koznyshev, who had also come out of the porch displeased Levin by the feigned friendliness with which he greeted Oblonsky, whom, as Levin knew, he neither liked nor respected.\n",
      "    TARGET: Perfino Sergej Ivanovic, uscito anche lui sulla scalinata, non gli riuscì gradito per quella finta benevolenza con cui accolse Stepan Arkad’ic, quando egli sapeva che suo fratello non amava Oblonskij e non lo stimava.\n",
      " PREDICTED: Anche Sergej Ivanovic , che aveva già portato la scala , era pure felice dal fatto che Levin aveva preso con la religione , non sapeva bene né perché non lo amava .\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: 'MLLE VARENKA! WHEN VERY YOUNG I formed my ideal of the woman I should love and whom I should be happy to call my wife.\n",
      "    TARGET: “Varvara Andreevna, quando ero ancora molto giovane mi sono formato l’ideale della donna che avrei voluto amare ed essere felice di chiamare mia moglie.\n",
      " PREDICTED: — , signora , la gioia di quella donna e di cui voglio amare la moglie e la moglie .\n",
      "--------------------------------------------------------------------------------\n",
      "Creating Checkpoint..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: It was Levin's face with his kind eyes looking mournfully from under his knit brows as he stood listening to her father and glancing at her and at Vronsky, and she felt so sorry for him that tears rose to her eyes.\n",
      "    TARGET: Era il viso di Levin con le sopracciglia aggrottate e gli occhi buoni che guardavano di sotto in su, scoraggiati e tristi, mentre, in piedi, ascoltava suo padre e guardava lei e Vronskij. E provò tanta pena per lui che le vennero le lacrime agli occhi.\n",
      " PREDICTED: Era il viso di Levin , con gli occhi scintillanti , con le sopracciglia scintillanti , che , in particolare il padre , si era fermato e , guardando di lui , Vronskij , lo guardava con orrore e lacrime .\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: Karenin flushed, and pulling away his hand left the room.\n",
      "    TARGET: Aleksej Aleksandrovic s’infiammò, e, svincolato bruscamente il braccio, uscì dalla stanza in silenzio.\n",
      " PREDICTED: Aleksej Aleksandrovic , in viso e , per la mano , si accostò al suo posto .\n",
      "--------------------------------------------------------------------------------\n",
      "Creating Checkpoint..\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: 'You didn't believe it, my darling?'\n",
      "    TARGET: — Non ci credevi, piccolo mio?\n",
      " PREDICTED: — Non lo credi forse , mia cara ?\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: All the good counsels of my parents, my father’s tears and my mother’s entreaties, came now fresh into my mind; and my conscience, which was not yet come to the pitch of hardness to which it has since, reproached me with the contempt of advice, and the breach of my duty to God and my father.\n",
      "    TARGET: Tutti i buoni consigli de’ miei genitori, le lagrime di mio padre, le preghiere di mia madre, mi si rinfrescarono nella memoria; e la mia coscienza che non era anche giunta a quell’eccesso d’indurimento, cui pervenne più tardi, mi rinfacciava il disprezzo de’ suggerimenti ricevuti e la violazione de’ miei doveri verso Dio e i miei genitori.\n",
      " PREDICTED: Tutti i miei timori , il mio padre e la madre del mio cuore si era posto dinanzi a me ; la coscienza della mia coscienza era tornato in mezzo a me ; la coscienza non era tuttavia il peso di Dio che mi ha ; il diritto di e la mia opinione su la mia , la e la mia , la giustizia di Dio e il padre .\n",
      "--------------------------------------------------------------------------------\n",
      "Creating Checkpoint..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainer.fit(model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader)\n",
    "#             ckpt_path=\"/ERAv1/session15_assignment/weights/s15Model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1071b13f-39e0-4938-a2f8-e91a52a1cb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-a5a93b19430f7ca4\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-a5a93b19430f7ca4\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# start tensorboard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad34a77d-b2c3-4638-a06d-c1b9f6e884ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fastai2022)",
   "language": "python",
   "name": "fastai2022"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
